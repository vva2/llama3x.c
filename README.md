# llama3x.c

The project involves building a system from scratch to perform inference on
the LLama3.1 8B and LLama3.2 1B, 3B, and 11B models using pure C. 

Evaluation is done on TriviaQA, MMLU, CommonsenseQA

### Todo

- refer karpathy/llama2 video on youtube
- convert tokenizer to bin file
- read tokenizer in c
- convert model to bin file
- read model in c
- check params
- can implement trie based token search while still being memory efficient.

### Links

- https://github.com/jameswdelancey/llama3.c
- https://github.com/karpathy/llama2.c